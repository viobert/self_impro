# GPT-4 IS HERE: WHAT SCIENTISTS THINK

20230330  *Nature*



## 原文

### GPT-4 IS HERE: WHAT SCIENTISTS THINK

*Researchers are excited about the AI, but frustrated by the secrecy surrounding its underlying engineering.* 

**By Katharine Sanderson**

Artificial intelligence (AI) company OpenAI this week unveiled GPT-4, the latest incarnation of the large language model that powers its pop-ular chatbot ChatGPT. The company says GPT-4 contains big improvements — it has already stunned people with its ability to create text resembling that written by humans and generate images and computer code from almost any prompt. Researchers say these abilities have the potential to transform science — but some are frustrated that they cannot yet access the technology, its underlying code or information on how it was trained. That raises concern about the technology’s safety and makes it less useful for research, say scientists. 

GPT-4 was released on 14 March, and one upgrade is that it can now handle images as well as text. And as a demonstration of its language prowess, OpenAI, which is based in San Francisco, California, says that it passed the US bar legal exam with results in the ninetieth centile, compared with the tenth centile for the previous version of ChatGPT. But the technology is not yet widely accessible — only paying subscribers so far have access. 

“There’s a waiting list at the moment so you cannot use it right now,” says Evi-Anne van Dis, a psychologist at the University of Amsterdam Medical Centers. But she has seen demos of GPT-4. “We watched some videos in which they demonstrated capacities and it’s mind-blowing,” she says. One instance, she recounts, was a hand-drawn doodle of a website, which GPT-4 used to produce the computer code needed to build that website, as a demonstration of the ability to handle images as inputs. 

#### Black box

But there is frustration in the science community over OpenAI’s secrecy around how the model was trained and what data were used, and how GPT-4 actually works. “All of these closed-source models, they are essentially dead ends in science,” says Sasha Luccioni, a research scientist specializing in climate at HuggingFace, an open-source AI cooperative. “They [OpenAI] can keep building upon their research, but for the community at large, it’s a dead end.” 

Andrew White, a chemical engineer at the University of Rochester, New York, has had privileged access to GPT-4 as a ‘red-teamer’: a person paid by OpenAI to test the platform to try and make it do something bad. He has had access to GPT-4 for the past six months, he says. “Early on in the process, it didn’t seem that different,” compared with previous iterations. 

He put to the bot queries about what chem-ical reaction steps were needed to make a compound, predict the reaction yield and choose a catalyst. “At first, I was actually not that impressed,” White says. “It was really surprising because it would look so realistic, but it would hallucinate an atom here. It would skip a step there,” he adds. But when, as part of his red-team work, he gave GPT-4 access to scientific papers, things changed drastically. “It made us realize that these models maybe aren’t so great just alone. But when you start connecting them to the Internet to tools like a retrosynthesis planner, or a calculator, all of a sudden, new kinds of abilities emerge.” 

#### Danger prevention

And with those abilities come concerns. For instance, could GPT-4 allow dangerous chemicals to be made? With input from people such as White, OpenAI engineers fed back into their model to discourage GPT-4 from creating dangerous, illegal or damaging con-tent, White says. 

Outputting false information is another problem. Luccioni says that models such as GPT-4, which exist to predict the next word in a sentence, can’t be cured of coming up with fake facts — known as hallucinating. “You can’t rely on these kinds of models because there’s so much hallucination,” she says. And this remains a concern in the latest version, she says, although OpenAI says that it has improved safety in GPT-4. 

Without access to the data used for training, OpenAI’s assurances about safety fall short for Luccioni. “You don’t know what the data is. So you can’t improve it. I mean, it’s just com-pletely impossible to do science with a model like this,” she says. The mystery about how GPT-4 was trained is also a concern for van Dis’s colleague at Amsterdam, psychologist Claudi Bockting. “It’s very hard as a human being to be account-able for something that you cannot oversee,” she says.

 “One of the concerns is they could be far more biased than, for instance, the bias that human beings have by themselves.” Without being able to access the code behind GPT-4, it is impossible to see where the bias might have originated, or to remedy it, Luccioni explains. 

#### Ethics discussions

Bockting and van Dis are also concerned that these AI systems are increasingly owned by big tech companies. The researchers want to make sure the technology is properly tested and ver-ified by scientists. “This is also an opportunity because collaboration with big tech can, of course, speed up processes,” she adds. 

Van Dis, Bockting and colleagues argued earlier this year that there is an urgent need to develop a set of ‘living’ guidelines to gov-ern how AI and tools such as GPT-4 are used and developed. They are concerned that any legislation around AI technologies will strug-gle to keep up with the pace of development. Bockting and van Dis have convened a sum-mit of invited participants at the University of Amsterdam on 11 April to discuss these concerns, with representatives from organi-zations including the science-ethics commit-tee of UNESCO, the United Nations’ scientific and cultural agency, the Organisation for Eco-nomic Co-operation and Development and the World Economic Forum. 

Despite the concern, GPT-4 and its future iterations will shake up science, says White. “I think it’s actually going to be a huge infrastruc-ture change in science, almost like the Inter-net was a big change,” he says. It won’t replace scientists, he adds, but could help with some tasks. “I think we’re going to start realizing we can connect papers, data programs, libraries that we use and computational work or even robotic experiments.” 





## 阅读

### GPT-4 IS HERE: WHAT SCIENTISTS THINK

*Researchers are excited about the AI, but frustrated by the secrecy surrounding its underlying engineering.* 

> + surrounding its underlying engineering 作后置定语 修饰名词`secrecy`
> + secrecy   n. 秘密
> + underlying
>     + important in a situation but not always easily noticed or stated clearly
>     + existing under the surface of sth else ✅
> + 科学家对ai表示兴奋不已的同时，对它的底层技术表示困惑

**By Katharine Sanderson**

Artificial intelligence (AI) company OpenAI this week ==unveiled== GPT-4, the latest ==incarnation== of the large language model that powers its pop-ular chatbot ChatGPT. The company says GPT-4 contains big improvements — it has already stunned people with its ability to create text ==resembling== that written by humans and generate images and computer code from almost any ==prompt==. Researchers say these abil-ities have the potential to transform science — but some are frustrated that they cannot yet access the technology, its underlying code or information on how it was trained. ^^That raises concern about the technology’s safety and makes it less useful for research, say scientists. ^^

> + unveil
>     + veil   n. 面纱
>     + unveil 解开面纱    v. 首次展示，推出
>     + to show sth. or make it known for the first time (release/launch)
> + incarnation   n. 化身，具体体现
>     + He was the incarnation of evil.
> + resemble   v. 像
>     + to look like sb. or sth.
>     + After the earthquake, the city resembled a battlefeild. 看起来像经历过一场战争。
> + prompt   n. 提示符 v. 提示鼓励
>     + a sign on a computer screen that shows that the computer is ready to receive your instructions.
> + That raises concern about the technology’s safety and makes it less useful for research, say scientists. 
>     + That raises concern about...  引起人们的担忧
>     + The soaring population has raised concerns about the food security.

GPT-4 was released on 14 March, and one upgrade is that it can now handle images as well as text. And as a demonstration of its language ==prowess==, OpenAI, which is based in San Francisco, California, says that it passed the US ==bar legal exam== with results in the nineti-eth ==centile==, compared with the tenth centile for the previous version of ChatGPT. But the technology is not yet widely accessible — only paying subscribers so far have access. 

> + prowess   n. 才能，技能  (great ability or skill)
> + bar legal exam 律师资格考试
> + centile   n. 百分数位

“There’s a waiting list at the moment so you cannot use it right now,” says Evi-Anne van Dis, a psychologist at the University of Amsterdam Medical Centers. But she has seen demos of GPT-4. “We watched some videos in which they ==demonstrated== capacities and it’s ==mind-blowing==,” she says. One instance, she ==recounts==, was a hand-drawn ==doodle== of a website, which GPT-4 used to produce the computer code needed to build that website, as a demonstration of the ability to handle images as inputs. 

> + demonstrated   adj. 演示的
> + mind-blowing  a.  令人叹为观止的
>     + The special effects in this film are pretty mind-blowing.
> + recount   v. 讲述
> + doodle   n.&v. 乱涂乱画

#### Black box

But there is frustration in the science community over OpenAI’s secrecy around how the model was trained and what data were used, and how GPT-4 actually works. “All of these ==closed-source== models, they are essentially dead ends in science,” says Sasha Luccioni, a research scientist== specializing in climate== at HuggingFace, an ==open-source== AI cooperative. “They [OpenAI] can keep building upon their research, but for the community ==at large==, it’s a dead end.” 

> + community   n. 群体，团队，界
>     + 很常用的表达  “界”
>     + the science/scientific community  科学界
>     + academic community   学术界
>     + international community   全世界
>     + local community   当地
> +  closed-source  闭源的
> + open-source  开源的
> +  specializing in climate 做定语，研究气候的
> + at large   普遍，全体（generally）
>     + There are some valuable lessons which the world at large can learn from this accident. 
>     + 从这个事故给全世界带来了宝贵的经验。
> + it’s a dead end   这是一条死胡同
>     + 英语中有个规则，当用两个以上的单词合成词组加连词符，词组来修饰一个名词要放在前面。
>     + My career has hit a dead end.
>     + It is a dead-end job.

Andrew White, a chemical engineer at the University of Rochester, New York, has had ==privileged== access to GPT-4 as a ==‘red-teamer’==: a person paid by OpenAI to test the platform to try and make it do something bad. He has had access to GPT-4 for the past six months, he says. “==Early on== in the process, it didn’t seem that different,” compared with previous ==iterations==. 

> + privileged   a. 享有特权的
>     +  having or showing a special advantage
>     + Shareholders may have privileged access to important information.   股东享有优先特权
> + red-teamer
>     + a cybersecurity professional that works to help companies improve IT security frameworks by attacking and undermining those same frameworks.
>     + 可以理解为白客，不过挺有趣的是单词本身是red-teamer，红客hh
> + Early on   早前
> + iteration   n. 迭代

He put to the bot queries about what chemical reaction steps were needed to make a compound, predict the ==reaction yield== and choose a ==catalyst==. “At first, I was actually not that impressed,” White says. “It was really surprising because it would look so realistic, but it would ==hallucinate== an atom here. It would skip a step there,” he adds. But when, as part of his red-team work, he gave GPT-4 access to scientific papers, things changed drastically. “It made us realize that these models maybe aren’t so great just alone. But when you start connecting them to the Internet to tools like a ==retrosynthesis== planner, or a calculator, all of a sudden, new kinds of abilities emerge.” 

> + compound   n. 化合物
>     + Salt is a compound of sodium and chlorine.   盐是由钠和氯
> + reaction yield  反应产率
> + catalyst   催化剂
> + retrosynthesis   逆合成
> + hallucinate   v. 产生幻觉      这里文中是指，GPT自己**编**的答案(自己**虚构**的原子)就跟真的一样。后面说给了一片论文重新学习，他的表现让人mind-blowing
>     + Mental disorders, drugs use, and hypnosis can all cause people to hallucinate.
> + 

#### Danger prevention

And with those abilities ==come concerns==. For instance, could GPT-4 allow dangerous chemicals to be made? With input from people such as White, OpenAI engineers fed back into their model to discourage GPT-4 from creating dangerous, illegal or damaging content, White says. 

> + come concerns        这短语太常见了

Outputting false information is another problem. Luccioni says that models such as GPT-4, which exist to predict the next word in a sentence, can’t be cured of coming up with fake facts — known as ==hallucinating==. “You can’t rely on these kinds of models because there’s so much hallucination,” she says. And this remains a concern in the latest version, she says, although OpenAI says that it has improved safety in GPT-4. 

> + hallucinating   这里又出现了，编造行为称为 hallucinate.  问了个专业人士，这个词行内翻译为**幻象**

Without access to the data used for training, OpenAI’s assurances about safety ==fall short== for Luccioni. “You don’t know what the data is. So you can’t improve it. I mean, it’s just com-pletely impossible to do science with a model like this,” she says. The mystery about how GPT-4 was trained is also a concern for van Dis’s colleague at Amsterdam, psychologist Claudi Bockting. “It’s very hard as a human being to be ==accountable== for something that you cannot ==oversee==,” she says.

> + fall short  不符合，不达标
>     + to fail to reach an amount or standard that was expected or hoped for.
>     + Why is it that on paper the drive for organization seems a sure shot for increasing productivity, but in reality **falls well short** of what is expected?
>         + 这例句不好理解
>         + on paper  理论上      后面有个 in reality  对应
>         + drive  意思很多，这里想表达`方法，有组织的努力`
>             + an organized effort by a group of people to achieve sth
>         + 为什么理论上一些方法看上去能给组织提高生产力，但是实际上往往远远达不到大家的预期。
> + accountable  a. 负责任的
>     + He knew he would be held accountable for any flaws in the programming.
> + oversee   v. 监督监管
>     + As marketing manager, her job is to oversee all the **company's advertising**. 市场营销

 “One of the concerns is they could be far more biased than, for instance, the bias that human beings have by themselves.” Without being able to access the code behind GPT-4, it is impossible to see where the bias might have originated, or to ==remedy== it, Luccioni explains. 

> + remedy   n. 解药，解决方法  & v.
>     + a successful way of curing an illness or dealing with a problem or difficulty.
>     + The best remedy for grief is hard work.



#### Ethics discussions

Bockting and van Dis are also concerned that these AI systems are increasingly owned by big tech companies. The researchers want to make sure the technology is properly tested and ver-ified by scientists. “This is also an opportunity because ==collaboration== with big tech can, of course, speed up processes,” she adds. 

> + collaboration   n. 合作    collaborate
>     + The two playwrights worked in close collaboration on the script.
>     + playwrights 编剧     script 剧本

Van Dis, Bockting and colleagues argued earlier this year that there is an urgent need to develop a set of ‘living’ guidelines to gov-ern how AI and tools such as GPT-4 are used and developed. They are concerned that any ==legislation== around AI technologies will strug-gle to keep up with the pace of development. Bockting and van Dis have ==convened== a summit of invited participants at the University of Amsterdam on 11 April to discuss these concerns, with representatives from organizations including the science-ethics commit-tee of UNESCO, the United Nations’ scientific and cultural agency, the Organisation for Economic Co-operation and Development and the World Economic Forum. 

> + legislation  n. 立法，法律
>     + The government has promised to in troduce legislation to limit fuel emissions from cars.
> + convened   v. 召集

Despite the concern, GPT-4 and its future iterations will ==shake up== science, says White. “I think it’s actually going to be a huge infrastruc-ture change in science, almost like the Inter-net was a big change,” he says. It won’t replace scientists, he adds, but could help with some tasks. “I think we’re going to start realizing we can connect papers, data programs, libraries that we use and computational work or even robotic experiments.” 

> + shake up  巨大的变化   to cause large changes in sth.
>     + game changer
>     + Technological changes have shaken up many industries.
>     + The company is undergoing a radical shake-up.

